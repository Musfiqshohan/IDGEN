{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:41.681137Z",
     "start_time": "2024-10-28T20:35:40.730074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "2+2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:44.821069Z",
     "start_time": "2024-10-28T20:35:44.439811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "\n",
    "print('imported')\n",
    "\n",
    "bn=gum.BayesNet('frontdoor')\n",
    "U,X,Z,Y=[ bn.add(name, 2) for name in \"UXZY\" ] \n",
    "print (bn)\n",
    "\n",
    "all_nodes=['U', 'X','Z', 'Y'] \n",
    "\n",
    "bn.addArc(U,X)\n",
    "bn.addArc(U,Y)\n",
    "bn.addArc(X,Z)\n",
    "bn.addArc(Z,Y)\n",
    "gnb.flow.row(bn)\n",
    "\n",
    "bn"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n",
      "BN{nodes: 4, arcs: 0, domainSize: 16, dim: 4, mem: 64o}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <style>\n",
       "      .floating-box {\n",
       "      display: inline-block;\n",
       "      margin: 7px;\n",
       "      padding : 3px;\n",
       "      border: 0px solid transparent;  \n",
       "      valign:middle;\n",
       "      background-color: transparent;\n",
       "      }\n",
       "      </style>\n",
       "      <div class=\"floating-box\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"89pt\" height=\"260pt\" viewBox=\"0.00 0.00 89.00 260.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>G</title>\n",
       "<!-- U -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>U</title>\n",
       "<g id=\"a_node1\"><a xlink:title=\"(0) U\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"54\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">U</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X</title>\n",
       "<g id=\"a_node2\"><a xlink:title=\"(1) X\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">X</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- U&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>U-&gt;X</title>\n",
       "<g id=\"a_edge1\"><a xlink:title=\"0 → 1\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M47.6,-216.41C44.49,-208.34 40.67,-198.43 37.17,-189.35\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"40.4,-188.03 33.54,-179.96 33.87,-190.55 40.4,-188.03\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"(3) Y\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Y</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- U&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>U-&gt;Y</title>\n",
       "<g id=\"a_edge3\"><a xlink:title=\"0 → 3\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M57.65,-215.91C59.68,-205.57 61.98,-192.09 63,-180 67.03,-132.17 67.03,-119.83 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<g id=\"a_node4\"><a xlink:title=\"(2) Z\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Z</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Z -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>X-&gt;Z</title>\n",
       "<g id=\"a_edge2\"><a xlink:title=\"1 → 2\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M27,-143.7C27,-135.98 27,-126.71 27,-118.11\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Z&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Z-&gt;Y</title>\n",
       "<g id=\"a_edge4\"><a xlink:title=\"2 → 3\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "</g>\n",
       "</svg></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(pyAgrum.BayesNet<double>@0x55906cde69c0) BN{nodes: 4, arcs: 4, domainSize: 16, dim: 9, mem: 144o}"
      ],
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"89pt\" height=\"260pt\" viewBox=\"0.00 0.00 89.00 260.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>G</title>\n",
       "<!-- U -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>U</title>\n",
       "<g id=\"a_node1\"><a xlink:title=\"(0) U\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"54\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">U</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X</title>\n",
       "<g id=\"a_node2\"><a xlink:title=\"(1) X\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">X</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- U&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>U-&gt;X</title>\n",
       "<g id=\"a_edge1\"><a xlink:title=\"0 → 1\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M47.6,-216.41C44.49,-208.34 40.67,-198.43 37.17,-189.35\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"40.4,-188.03 33.54,-179.96 33.87,-190.55 40.4,-188.03\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"(3) Y\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Y</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- U&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>U-&gt;Y</title>\n",
       "<g id=\"a_edge3\"><a xlink:title=\"0 → 3\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M57.65,-215.91C59.68,-205.57 61.98,-192.09 63,-180 67.03,-132.17 67.03,-119.83 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<g id=\"a_node4\"><a xlink:title=\"(2) Z\">\n",
       "<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Z</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Z -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>X-&gt;Z</title>\n",
       "<g id=\"a_edge2\"><a xlink:title=\"1 → 2\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M27,-143.7C27,-135.98 27,-126.71 27,-118.11\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"30.5,-118.1 27,-108.1 23.5,-118.1 30.5,-118.1\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- Z&#45;&gt;Y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Z-&gt;Y</title>\n",
       "<g id=\"a_edge4\"><a xlink:title=\"2 → 3\">\n",
       "<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:45.606114Z",
     "start_time": "2024-10-28T20:35:45.599059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bn.generateCPT('U')\n",
    "bn.generateCPT('X')\n",
    "bn.generateCPT('Z')\n",
    "bn.generateCPT('Y')\n",
    "\n",
    "ie=gum.LazyPropagation(bn)\n",
    "ie.makeInference()\n",
    "ie.evidenceJointImpact(['X', 'Z', 'Y'], [])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyAgrum.Potential<double>@0x55906cd26df0) \n",
       "             ||  Y                |\n",
       "X     |Z     ||0        |1        |\n",
       "------|------||---------|---------|\n",
       "0     |0     || 0.0253  | 0.0737  |\n",
       "1     |0     || 0.0862  | 0.4097  |\n",
       "0     |1     || 0.1020  | 0.0945  |\n",
       "1     |1     || 0.1080  | 0.1006  |"
      ],
      "text/html": [
       "<table style=\"border:1px solid black;border-collapse: collapse;\">\n",
       "<tr><th colspan='2'></th>\n",
       "      <th colspan='2' style='border:1px solid black;color:black;background-color:#808080;'><center>Y</center>\n",
       "      </th></tr>\n",
       "<tr><th style='border:1px solid black;color:black;background-color:#808080'><center>Z</center></th><th style='border:1px solid black;color:black;background-color:#808080'><center>X</center></th><th style='border:1px solid black;border-bottom-style: double;color:black;background-color:#BBBBBB'>\n",
       "      <center>0</center></th><th style='border:1px solid black;border-bottom-style: double;color:black;background-color:#BBBBBB'>\n",
       "      <center>1</center></th></tr>\n",
       "<tr><th style='border:1px solid black;color:black;background-color:#BBBBBB;' rowspan = '2'>\n",
       "            <center>0</center></th><th style='border:1px solid black;color:black;background-color:#BBBBBB'><center>0</center></th><td style='color:black;background-color:#fb8264;text-align:right;padding: 3px;'>0.0253</td><td style='color:black;background-color:#f58864;text-align:right;padding: 3px;'>0.0737</td></tr>\n",
       "<tr><th style='border:1px solid black;color:black;background-color:#BBBBBB'><center>1</center></th><td style='color:black;background-color:#f38a64;text-align:right;padding: 3px;'>0.0862</td><td style='color:black;background-color:#cab364;text-align:right;padding: 3px;'>0.4097</td></tr>\n",
       "<tr><th style='border:1px solid black;color:black;background-color:#BBBBBB;' rowspan = '2'>\n",
       "            <center>1</center></th><th style='border:1px solid black;color:black;background-color:#BBBBBB'><center>0</center></th><td style='color:black;background-color:#f18c64;text-align:right;padding: 3px;'>0.1020</td><td style='color:black;background-color:#f28b64;text-align:right;padding: 3px;'>0.0945</td></tr>\n",
       "<tr><th style='border:1px solid black;color:black;background-color:#BBBBBB'><center>1</center></th><td style='color:black;background-color:#f18c64;text-align:right;padding: 3px;'>0.1080</td><td style='color:black;background-color:#f28b64;text-align:right;padding: 3px;'>0.1006</td></tr>\n",
       "</table>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:46.956333Z",
     "start_time": "2024-10-28T20:35:46.943275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# intervened graph         \n",
    "def get_bn(bn2, intervened):\n",
    "    for var in intervened:\n",
    "        for parent in bn2.cpt(var).var_names:\n",
    "            if parent != var:\n",
    "                bn2.eraseArc(*(parent, var))\n",
    "\n",
    "\n",
    "        lst = [0 for i in range(2)]\n",
    "        lst[intervened[var]] = 1\n",
    "        print(lst)\n",
    "        bn2.cpt(var).fillWith(lst)\n",
    "\n",
    "    return bn2\n",
    "\n",
    "# Ground True intervention     \n",
    "intervened={'X':1}\n",
    "bn_intv=gum.BayesNet(bn)\n",
    "bn_intv= get_bn(bn_intv, intervened)\n",
    "\n",
    "all_nodes=['U', 'Z','X', 'Y'] \n",
    "ie = gum.LazyPropagation(bn_intv)\n",
    "var_set = set(all_nodes)\n",
    "ie.addJointTarget(var_set)\n",
    "ie.makeInference()\n",
    "\n",
    "pY_dox= ie.evidenceJointImpact(['Y'],[])\n",
    "gnb.flow.row(pY_dox, captions=[f'P(Y|do{intervened})'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/a/rahman89/PycharmProjects/common-env/venv/lib/python3.10/site-packages/pyAgrum/pyAgrum.py:10018: UserWarning: \n",
      "** pyAgrum.Potential.var_names is obsolete in pyAgrum>0.22.9. Please use pyAgrum.Potential.names.\n",
      "\n",
      "  warnings.warn(\"\\n** pyAgrum.Potential.var_names is obsolete in pyAgrum>0.22.9. Please use pyAgrum.Potential.names.\\n\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <style>\n",
       "      .floating-box {\n",
       "      display: inline-block;\n",
       "      margin: 7px;\n",
       "      padding : 3px;\n",
       "      border: 0px solid transparent;  \n",
       "      valign:middle;\n",
       "      background-color: transparent;\n",
       "      }\n",
       "      </style>\n",
       "      <div class=\"floating-box\"><table style=\"border:1px solid black;border-collapse: collapse;\">\n",
       "<tr style='border:1px solid black;color:black;background-color:#808080'>\n",
       "      <th colspan='2'><center>Y</center></th></tr>\n",
       "<tr><th style='border:1px solid black;border-bottom-style: double;color:black;background-color:#BBBBBB'>\n",
       "      <center>0</center></th><th style='border:1px solid black;border-bottom-style: double;color:black;background-color:#BBBBBB'>\n",
       "      <center>1</center></th></tr>\n",
       "<tr><td style='color:black;background-color:#d9a464;text-align:right;padding: 3px;'>0.2929</td><td style='color:black;background-color:#a4d964;text-align:right;padding: 3px;'>0.7071</td></tr>\n",
       "</table><br><center><small><em>P(Y|do{'X': 1})</em></small></center></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:47.635964Z",
     "start_time": "2024-10-28T20:35:47.632669Z"
    }
   },
   "cell_type": "code",
   "source": "true_doX_cpt= pY_dox",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:48.417007Z",
     "start_time": "2024-10-28T20:35:48.411711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "true_doX={}\n",
    "for x in true_doX_cpt.loopIn():\n",
    "    # print(x.todict(), true_doX_cpt[x])\n",
    "    true_doX[tuple(x.todict().values())]= true_doX_cpt[x]\n",
    "\n",
    "true_doX"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,): 0.29286194666823534, (1,): 0.7071380533317647}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data generation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:49.721828Z",
     "start_time": "2024-10-28T20:35:49.563511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g=gum.BNDatabaseGenerator(bn)\n",
    "N= 10000\n",
    "g.drawSamples(N,{})\n",
    "dataset= g.to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "dataset = np.array(dataset).astype(int)\n",
    "\n",
    "dataset= dataset[:, 1:]  #ignoring the first one column for U as it is a latent\n",
    "\n",
    "\n",
    "\n",
    "unique_rows, counts = np.unique(dataset, axis=0, return_counts=True)\n",
    "\n",
    "\n",
    "joint_distribution = counts / len(dataset)\n",
    "\n",
    "# Print the unique rows and their corresponding probabilities\n",
    "for row, prob in zip(unique_rows, joint_distribution):\n",
    "    print(f\"Row: {row}, Probability: {prob:.4f}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: [0 0 0], Probability: 0.0263\n",
      "Row: [0 0 1], Probability: 0.0755\n",
      "Row: [0 1 0], Probability: 0.1017\n",
      "Row: [0 1 1], Probability: 0.0908\n",
      "Row: [1 0 0], Probability: 0.0882\n",
      "Row: [1 0 1], Probability: 0.4021\n",
      "Row: [1 1 0], Probability: 0.1125\n",
      "Row: [1 1 1], Probability: 0.1029\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:50.478896Z",
     "start_time": "2024-10-28T20:35:50.451329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# N=10000\n",
    "# sampleZ = np.random.binomial(n=1, p=pz[id,1], size=N)\n",
    "# sampleX_Z = np.random.binomial(n=1, p=px_z[id,1], size=N)\n",
    "# sampleY_XZ = np.random.binomial(n=1, p=py_xz[id,1], size=N)\n",
    "\n",
    " \n",
    "\n",
    "sampleX = torch.nn.functional.one_hot(torch.tensor(dataset[:,0]), num_classes=2).float()\n",
    "sampleZ = torch.nn.functional.one_hot(torch.tensor(dataset[:,1]), num_classes=2).float()  \n",
    "sampleY = torch.nn.functional.one_hot(torch.tensor(dataset[:,2]), num_classes=2).float()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training code"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:52.578706Z",
     "start_time": "2024-10-28T20:35:52.566308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature, gumbel_noise):\n",
    "\n",
    "    if gumbel_noise==None:\n",
    "        gumbel_noise= sample_gumbel(logits.size())\n",
    "\n",
    "    y = logits + gumbel_noise\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature, gumbel_noise=None, hard=False):\n",
    "    \"\"\"\n",
    "    ST-gumple-softmax\n",
    "    input: [*, n_class]\n",
    "    return: flatten --> [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    output_dim =logits.shape[1]\n",
    "    y = gumbel_softmax_sample(logits, temperature, gumbel_noise)\n",
    "\n",
    "    if not hard:\n",
    "        ret = y.view(-1, output_dim)\n",
    "        return ret\n",
    "\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "    y_hard = (y_hard - y).detach() + y\n",
    "    # ret = y_hard.view(-1, output_dim)\n",
    "    ret = y_hard.view(-1, output_dim)\n",
    "    return ret\n",
    "\n",
    "\n",
    "class SampleGenerator(nn.Module):\n",
    "    def __init__(self, input_size, output_size=2):\n",
    "        super(SampleGenerator, self).__init__()\n",
    "        hidden_size=50\n",
    "        # Define learnable latent parameter (no input needed)\n",
    "        self.latent = nn.Parameter(torch.randn(N, hidden_size))\n",
    "        \n",
    "        # if input_size==0:\n",
    "        input_size= input_size+ hidden_size\n",
    "        \n",
    "        # Define the layers\n",
    "        self.fc0 = nn.Linear(input_size, hidden_size)  # Hidden layer\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)  # Hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Output layer to predict logits\n",
    "\n",
    "    def forward(self, parents, temperature=1.0, hard=False):\n",
    "        \n",
    "\n",
    "        if parents==None:\n",
    "            parents=self.latent\n",
    "        else:\n",
    "            parents= torch.tensor(parents)\n",
    "            parents= torch.cat([parents, self.latent], dim=1)\n",
    "        \n",
    "        # Use the learnable latent vector\n",
    "        x= torch.relu(self.fc0(parents))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        logits = torch.relu(self.fc2(x))\n",
    "                \n",
    "        \n",
    "        #\n",
    "        # logits = logits / torch.max(logits)  # normalize logits\n",
    "        #\n",
    "        \n",
    "        # Apply Gumbel-Softmax to generate differentiable one-hot like vectors\n",
    "        # gumbel_softmax_output = nn.functional.gumbel_softmax(logits, tau=temperature, hard=hard, eps=1e-10)\n",
    "        \n",
    "        gumbel_softmax_output= gumbel_softmax(logits , temperature, None, False)\n",
    "        \n",
    "        \n",
    "        output=gumbel_softmax_output\n",
    "        if torch.isnan(torch.max(output)):\n",
    "            print('--->',output.shape, ' logists-->', torch.max(logits),torch.min(logits), ' tau-->', temperature)\n",
    "        \n",
    "        \n",
    "        return gumbel_softmax_output\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:35:53.458273Z",
     "start_time": "2024-10-28T20:35:53.449275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def marginal(input, freq):\n",
    "    \n",
    "    if input==None:\n",
    "        comb=freq\n",
    "    else:\n",
    "        # inp= torch.argmax(input, dim=1).view(-1,1)\n",
    "        comb= torch.cat([freq, input], dim=1)\n",
    "            \n",
    "    unique_rows, counts = np.unique(np.array(comb), axis=0, return_counts=True)\n",
    "    joint_distribution = counts / len(dataset)\n",
    "    \n",
    "    rdict={}\n",
    "    for row, prob in zip(unique_rows, joint_distribution):\n",
    "        rdict[tuple(row)]= prob\n",
    "        # print(f\"Row: {row}, Probability: {prob:.4f}\")\n",
    "    \n",
    "    return rdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(input, targets, model):\n",
    "\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop (for one sample per forward pass)\n",
    "    for epoch in range(2000):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "    \n",
    "        # Forward pass to generate sample\n",
    "        output = model(input, temperature=1.0, hard=False)  # Model generates sample\n",
    "    \n",
    "        # Compute loss\n",
    "        loss = criterion(output, targets) #P(Y|X,Z)\n",
    "        \n",
    "        if torch.isnan(loss):\n",
    "            print(torch.max(output), torch.min(output))\n",
    "            break\n",
    "            \n",
    "\n",
    "        \n",
    "        # Backpropagation and optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if (epoch+1) % 50 == 0:\n",
    "            \n",
    "            freq= torch.argmax(output, dim=1).view(-1,1)\n",
    "            rdict= marginal(input, freq)\n",
    "            \n",
    "            \n",
    "            freq= torch.argmax(targets, dim=1).view(-1,1)\n",
    "            tdict= marginal(input, freq)\n",
    "                \n",
    "            tvd=0\n",
    "            for key in rdict:\n",
    "                tvd+= abs(rdict[key]- tdict[key])\n",
    "                \n",
    "\n",
    "\n",
    "            ###\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f} obsTVD:{tvd/2:0.4f}')\n",
    "            \n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train P(Y|X,Z)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:36:59.546248Z",
     "start_time": "2024-10-28T20:36:45.732679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input= torch.cat([sampleX, sampleZ], dim=1)\n",
    "targets = sampleY\n",
    "input_size=4\n",
    "\n",
    "modelY = SampleGenerator(input_size=input_size)  # P(Y|X,Z)\n",
    "modelY= train(input, targets, modelY)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1104894/3770493806.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  parents= torch.tensor(parents)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000], Loss: 0.6763 obsTVD:0.1331\n",
      "Epoch [100/1000], Loss: 0.5927 obsTVD:0.2335\n",
      "Epoch [150/1000], Loss: 0.4443 obsTVD:0.0596\n",
      "Epoch [200/1000], Loss: 0.3792 obsTVD:0.0377\n",
      "Epoch [250/1000], Loss: 0.3665 obsTVD:0.0329\n",
      "Epoch [300/1000], Loss: 0.3630 obsTVD:0.0300\n",
      "Epoch [350/1000], Loss: 0.3608 obsTVD:0.0287\n",
      "Epoch [400/1000], Loss: 0.3598 obsTVD:0.0279\n",
      "Epoch [450/1000], Loss: 0.3593 obsTVD:0.0272\n",
      "Epoch [500/1000], Loss: 0.3586 obsTVD:0.0266\n",
      "Epoch [550/1000], Loss: 0.3579 obsTVD:0.0260\n",
      "Epoch [600/1000], Loss: 0.3577 obsTVD:0.0258\n",
      "Epoch [650/1000], Loss: 0.3574 obsTVD:0.0255\n",
      "Epoch [700/1000], Loss: 0.3572 obsTVD:0.0253\n",
      "Epoch [750/1000], Loss: 0.3572 obsTVD:0.0253\n",
      "Epoch [800/1000], Loss: 0.3571 obsTVD:0.0254\n",
      "Epoch [850/1000], Loss: 0.3570 obsTVD:0.0253\n",
      "Epoch [900/1000], Loss: 0.3568 obsTVD:0.0251\n",
      "Epoch [950/1000], Loss: 0.3565 obsTVD:0.0248\n",
      "Epoch [1000/1000], Loss: 0.3560 obsTVD:0.0247\n",
      "Epoch [1050/1000], Loss: 0.3560 obsTVD:0.0247\n",
      "Epoch [1100/1000], Loss: 0.3558 obsTVD:0.0245\n",
      "Epoch [1150/1000], Loss: 0.3558 obsTVD:0.0245\n",
      "Epoch [1200/1000], Loss: 0.3556 obsTVD:0.0243\n",
      "Epoch [1250/1000], Loss: 0.3554 obsTVD:0.0243\n",
      "Epoch [1300/1000], Loss: 0.3554 obsTVD:0.0243\n",
      "Epoch [1350/1000], Loss: 0.3552 obsTVD:0.0242\n",
      "Epoch [1400/1000], Loss: 0.3550 obsTVD:0.0239\n",
      "Epoch [1450/1000], Loss: 0.3549 obsTVD:0.0238\n",
      "Epoch [1500/1000], Loss: 0.3548 obsTVD:0.0237\n",
      "Epoch [1550/1000], Loss: 0.3546 obsTVD:0.0235\n",
      "Epoch [1600/1000], Loss: 0.3546 obsTVD:0.0235\n",
      "Epoch [1650/1000], Loss: 0.3546 obsTVD:0.0235\n",
      "Epoch [1700/1000], Loss: 0.3545 obsTVD:0.0235\n",
      "Epoch [1750/1000], Loss: 0.3545 obsTVD:0.0234\n",
      "Epoch [1800/1000], Loss: 0.3543 obsTVD:0.0232\n",
      "Epoch [1850/1000], Loss: 0.3543 obsTVD:0.0232\n",
      "Epoch [1900/1000], Loss: 0.3543 obsTVD:0.0232\n",
      "Epoch [1950/1000], Loss: 0.3543 obsTVD:0.0232\n",
      "Epoch [2000/1000], Loss: 0.3543 obsTVD:0.0232\n",
      "Training complete!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train P(Z|X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:37:15.001932Z",
     "start_time": "2024-10-28T20:37:01.600861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input= torch.cat([sampleX], dim=1)\n",
    "targets = sampleZ\n",
    "input_size=2\n",
    "\n",
    "modelZ = SampleGenerator(input_size=input_size)  # P(Z|X)\n",
    "modelZ= train(input, targets, modelZ)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1104894/3770493806.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  parents= torch.tensor(parents)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000], Loss: 0.6763 obsTVD:0.2349\n",
      "Epoch [100/1000], Loss: 0.5153 obsTVD:0.0584\n",
      "Epoch [150/1000], Loss: 0.4081 obsTVD:0.0441\n",
      "Epoch [200/1000], Loss: 0.3802 obsTVD:0.0362\n",
      "Epoch [250/1000], Loss: 0.3736 obsTVD:0.0326\n",
      "Epoch [300/1000], Loss: 0.3705 obsTVD:0.0320\n",
      "Epoch [350/1000], Loss: 0.3680 obsTVD:0.0301\n",
      "Epoch [400/1000], Loss: 0.3668 obsTVD:0.0294\n",
      "Epoch [450/1000], Loss: 0.3660 obsTVD:0.0291\n",
      "Epoch [500/1000], Loss: 0.3649 obsTVD:0.0280\n",
      "Epoch [550/1000], Loss: 0.3648 obsTVD:0.0279\n",
      "Epoch [600/1000], Loss: 0.3642 obsTVD:0.0279\n",
      "Epoch [650/1000], Loss: 0.3636 obsTVD:0.0274\n",
      "Epoch [700/1000], Loss: 0.3629 obsTVD:0.0268\n",
      "Epoch [750/1000], Loss: 0.3627 obsTVD:0.0268\n",
      "Epoch [800/1000], Loss: 0.3625 obsTVD:0.0268\n",
      "Epoch [850/1000], Loss: 0.3622 obsTVD:0.0269\n",
      "Epoch [900/1000], Loss: 0.3619 obsTVD:0.0268\n",
      "Epoch [950/1000], Loss: 0.3619 obsTVD:0.0268\n",
      "Epoch [1000/1000], Loss: 0.3618 obsTVD:0.0267\n",
      "Epoch [1050/1000], Loss: 0.3618 obsTVD:0.0267\n",
      "Epoch [1100/1000], Loss: 0.3615 obsTVD:0.0264\n",
      "Epoch [1150/1000], Loss: 0.3615 obsTVD:0.0264\n",
      "Epoch [1200/1000], Loss: 0.3613 obsTVD:0.0262\n",
      "Epoch [1250/1000], Loss: 0.3609 obsTVD:0.0262\n",
      "Epoch [1300/1000], Loss: 0.3609 obsTVD:0.0262\n",
      "Epoch [1350/1000], Loss: 0.3608 obsTVD:0.0263\n",
      "Epoch [1400/1000], Loss: 0.3606 obsTVD:0.0261\n",
      "Epoch [1450/1000], Loss: 0.3604 obsTVD:0.0261\n",
      "Epoch [1500/1000], Loss: 0.3604 obsTVD:0.0261\n",
      "Epoch [1550/1000], Loss: 0.3602 obsTVD:0.0259\n",
      "Epoch [1600/1000], Loss: 0.3598 obsTVD:0.0257\n",
      "Epoch [1650/1000], Loss: 0.3597 obsTVD:0.0257\n",
      "Epoch [1700/1000], Loss: 0.3597 obsTVD:0.0256\n",
      "Epoch [1750/1000], Loss: 0.3594 obsTVD:0.0253\n",
      "Epoch [1800/1000], Loss: 0.3594 obsTVD:0.0253\n",
      "Epoch [1850/1000], Loss: 0.3594 obsTVD:0.0254\n",
      "Epoch [1900/1000], Loss: 0.3594 obsTVD:0.0253\n",
      "Epoch [1950/1000], Loss: 0.3592 obsTVD:0.0253\n",
      "Epoch [2000/1000], Loss: 0.3591 obsTVD:0.0252\n",
      "Training complete!\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inferene"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:37:17.663283Z",
     "start_time": "2024-10-28T20:37:17.653807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "intval=1\n",
    "intval= intval*torch.ones(N).to(torch.int64)\n",
    "outX= torch.nn.functional.one_hot(intval, num_classes=2).float()\n",
    "\n",
    "outZ = modelZ(outX, temperature=1.0, hard=True)\n",
    "\n",
    "outY= modelY(torch.cat([sampleX, outZ], dim=1), temperature=1.0, hard=True)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1104894/3770493806.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  parents= torch.tensor(parents)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T20:37:18.785222Z",
     "start_time": "2024-10-28T20:37:18.776607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "outt= outY\n",
    "outt= torch.argmax(outt, dim=1).view(-1,1)\n",
    "unique_rows, counts = np.unique(np.array(outt.detach()), axis=0, return_counts=True)\n",
    "joint_distribution = counts / len(outt)\n",
    "joint_distribution"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3049, 0.6951])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
